{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92c1a0-5e3d-4f42-81eb-7e56176b38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LLMs (AI model at the core of Agent):\n",
    "\n",
    "LLMs - understands and generates human language\n",
    "- built on Transformer architecture (deep learning architecture based on the \"Attention\" algorithm)\n",
    "\n",
    "3 types of Transformers:\n",
    "- encoders\n",
    "    - take text (or other data) as input and outputs a dense representation (or embedding) of that text\n",
    "    - (use cases) text classification, semantic search, etc.\n",
    "\n",
    "- decoders\n",
    "    - generates new tokens to complete a sequence, one token at a time\n",
    "    - (use cases) text generation, chatbots, code generation\n",
    "\n",
    "- seq2seq (encoder-decoder)\n",
    "    - encoder processes the input sequence into a context representation, and decoder generates an output sequence\n",
    "    - (use cases) translation, summarization, etc. \n",
    "\n",
    "LLMs are decoder-based models\n",
    "(underlying principle of LLM) -- objective is to predict the next token, given a sequence of previous tokens\n",
    "token - a unit of information an LLM works with\n",
    "(think of token as a word, but for efficiency reasons, LLMs don't use whole words)\n",
    "Tokenization often works on sub-word units that can be combined\n",
    "example: tokens \"interest\" and \"ing\" can be combined to \"interesting\"\n",
    "or \"ed\" to form \"iterested\"\n",
    "\n",
    "- Each LLM has some special token specific to the model.\n",
    "- LLMs uses these tokens to open and close the structured components of its generation.\n",
    "example - to indicate the start or end of the sequence, message, or response\n",
    "- Most important is End of sequence token (EOS)\n",
    "- LLMs are autoregressive (output from one pass becomes the input for the next one)\n",
    "loop continues until the model predicts the next token to be the EOS token, at which point the model can stop\n",
    "\n",
    "- key aspect of Transformer architecture is Attention\n",
    "(not every word in the sentence is equally important, some words carry most meaning compared to others)\n",
    "- identifying relevant words <-- effective \n",
    "\n",
    "- Prompt <-- input sequence that we provide an LLM\n",
    "(careful design of prompt -- guide the generation of LLM towards the desired output)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
